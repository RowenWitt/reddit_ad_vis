{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "223bcdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "maps_key = os.getenv('MAP_API')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ca94d1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = 'https://api.pushshift.io/reddit/comment/search/?sort=desc&sort_type=created_utc&subreddit=u_Columbia1938'\n",
    "\n",
    "# Loading in pre-saved Columbia reddit posts\n",
    "with open('ex.json', 'r') as f:\n",
    "    ordered = json.load(f)\n",
    "\n",
    "# Loading in pre-built encoding schema\n",
    "with open('encoding.json', 'r') as f:\n",
    "    encoding = json.load(f)\n",
    "\n",
    "# Gets 25 reddit posts from the Columbia subreddit before a given date\n",
    "def get_25(end_date):\n",
    "    print(end_date)\n",
    "    url = q1 + '&before=' + str(end_date)\n",
    "    print(url)\n",
    "    resp = requests.get(url)\n",
    "    if resp.status_code == 200:\n",
    "        return resp.json()\n",
    "\n",
    "# Runs a location guess through the Google places API to get a lat and long\n",
    "def ask_google(df):\n",
    "    lats = []\n",
    "    lons = []\n",
    "    names = []\n",
    "    for ind in range(len(df)):\n",
    "        loc = df.iloc[ind]['post_body_utc']\n",
    "        if loc != '[deleted]':\n",
    "\n",
    "            foc = requests.get(maps_url.format(re.sub(' ', '%20', loc), maps_key))\n",
    "\n",
    "            resp = foc.json()\n",
    "\n",
    "            if resp['candidates'] != []:\n",
    "                lat = resp['candidates'][0]['geometry']['location']['lat']\n",
    "                lon = resp['candidates'][0]['geometry']['location']['lng']\n",
    "                name = resp['candidates'][0]['formatted_address'].lower()\n",
    "\n",
    "                lats.append(lat)\n",
    "                lons.append(lon)\n",
    "                names.append(name)\n",
    "            else:\n",
    "                lats.append('to_fix')\n",
    "                lons.append('to_fix')\n",
    "                names.append('to_fix')\n",
    "        else:\n",
    "            lats.append('to_delete')\n",
    "            lons.append('to_delete')\n",
    "            names.append('to_fix')\n",
    "    return lats, lons, names\n",
    "\n",
    "\n",
    "second = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7ee56d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = 't3_qfiysg'\n",
    "conv2 = 't3_py79a5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1be3eae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 50 checks of 193 for conversation 1\n",
      "Completed 100 checks of 193 for conversation 1\n",
      "Completed 150 checks of 193 for conversation 1\n",
      "Completed 50 checks of 63 for conversation 2\n",
      "conversation 1 pairs: 189 \n",
      " conversation 2 pairs: 62 \n",
      " taking  417.98276591300964 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# flattening nested dicts\n",
    "flattened_1 = []\n",
    "flattened_2 = []\n",
    "for i in ordered:\n",
    "    for j in ordered[i]:\n",
    "\n",
    "        if j['link_id'] == conv1:\n",
    "            flattened_1.append(j)\n",
    "        elif j['link_id'] == conv2:\n",
    "            flattened_2.append(j)\n",
    "        \n",
    "# getting all reddit-user location guesses with company replies first 'game' from pushshift\n",
    "pairs_1 = []\n",
    "for i in range(len(flattened_1)):\n",
    "    res = flattened_1[i]\n",
    "    orig = 'https://api.pushshift.io/reddit/comment/search/?link_id={}&ids={}'.format(conv1, res['parent_id'])\n",
    "    check = requests.get(orig)\n",
    "    if check.status_code == 200:\n",
    "        pairs_1.append([res, check.json()])\n",
    "    if i % 50 == 0 and i != 0:\n",
    "        print('Completed {} checks of {} for conversation 1'.format(i, len(flattened_1)))\n",
    "        \n",
    "        \n",
    "# getting all reddit-user location guesses with company replies for second 'game' from pushshift\n",
    "pairs_2 = []\n",
    "for i in range(len(flattened_2)):\n",
    "    res = flattened_2[i]\n",
    "    orig = 'https://api.pushshift.io/reddit/comment/search/?link_id={}&ids={}'.format(conv2, res['parent_id'])\n",
    "    check = requests.get(orig)\n",
    "    if check.status_code == 200:\n",
    "        pairs_2.append([res, check.json()])\n",
    "    if i % 50 == 0 and i != 0:\n",
    "        print('Completed {} checks of {} for conversation 2'.format(i, len(flattened_2)))\n",
    "        \n",
    "\n",
    "# only grabbing reddit posts with Columbia responses\n",
    "full_pairs_1 = [i for i in pairs_1 if i[1] != {'data': []}]\n",
    "full_pairs_2 = [i for i in pairs_2 if i[1] != {'data': []}]\n",
    "\n",
    "print('conversation 1 pairs:', len(full_pairs_1), '\\n conversation 2 pairs:', len(full_pairs_2), '\\n', 'taking ', time.time() - start, 'seconds')\n",
    "\n",
    "\n",
    "# selecting useful data from pushshift api response json objects (reducing feature count of future df)\n",
    "reduced_pairs_1 = []\n",
    "reduced_pairs_2 = []\n",
    "\n",
    "for i in full_pairs_1:\n",
    "    row = {\n",
    "        \"post_time_utc\":i[1]['data'][0]['created_utc'],\n",
    "        \"post_location_utc\":i[1]['data'][0]['body'],\n",
    "        \"post_body_utc\":i[1]['data'][0]['body'],\n",
    "        \"response_body\":i[0]['body'],\n",
    "        \"response_time\":i[0]['created_utc']\n",
    "    }\n",
    "    reduced_pairs_1.append(row)\n",
    "    \n",
    "for i in full_pairs_2:\n",
    "    row = {\n",
    "        \"post_time_utc\":i[1]['data'][0]['created_utc'],\n",
    "        \"post_location_utc\":i[1]['data'][0]['body'],\n",
    "        \"post_body_utc\":i[1]['data'][0]['body'],\n",
    "        \"response_body\":i[0]['body'],\n",
    "        \"response_time\":i[0]['created_utc']\n",
    "    }\n",
    "    reduced_pairs_2.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "834354e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning reduced pairs of reddit posts and Columbia responses into dataframes\n",
    "pairs_1 = pd.DataFrame(reduced_pairs_1)\n",
    "pairs_2 = pd.DataFrame(reduced_pairs_2)\n",
    "\n",
    "# Adding columns to specify which reddit posts these comments pertain to, post 1 or post 2.\n",
    "pairs_1['root_post'] = ['post_1'] * len(pairs_1)\n",
    "pairs_2['root_post'] = ['post_2'] * len(pairs_2)\n",
    "\n",
    "# Concatenating the two dataframes now that we can undo it.\n",
    "combined_heavy = pd.concat([pairs_1, pairs_2])\n",
    "\n",
    "# Encoding the reddit users guesses of the picture's location.\n",
    "combined_heavy['encoded'] = combined_heavy['response_body'].apply(lambda x: encoding[x])\n",
    "\n",
    "# Converting the time of the user post from utc time to a datetime object.\n",
    "combined_heavy['post_time'] = combined_heavy['post_time_utc'].apply(lambda x:datetime.datetime.fromtimestamp(x))\n",
    "\n",
    "# Renaming the response_time column.  It was incorrectly named.\n",
    "combined_heavy['response_time_utc'] = combined_heavy['response_time']\n",
    "\n",
    "# Converting the response_time_utc from utc time to a datetime object.\n",
    "combined_heavy['response_time'] = combined_heavy['response_time_utc'].apply(lambda x:datetime.datetime.fromtimestamp(x))\n",
    "\n",
    "# Ensuring no rows were lost\n",
    "assert len(combined_heavy) == (len(pairs_1) + len(pairs_2))\n",
    "\n",
    "# Removing partially implemented vector encodings\n",
    "combined_heavy['encoded_clean'] = combined_heavy['encoded'].apply(lambda x: re.sub('[^0-9+-]', '', x))\n",
    "\n",
    "# Define Google Places API url\n",
    "maps_url = 'https://maps.googleapis.com/maps/api/place/findplacefromtext/json?input={}&inputtype=textquery&fields=formatted_address%2Cname%2Cgeometry&key={}'\n",
    "\n",
    "# Applying Google Places API to each reddit user guess to obtain a latitude and longitude\n",
    "lats, lons, names = ask_google(combined_heavy)\n",
    "\n",
    "# Adding in new lat and lon columns\n",
    "combined_heavy['lat'] = lats\n",
    "combined_heavy['lon'] = lons\n",
    "combined_heavy['name'] = names\n",
    "\n",
    "# dropping duplicate and misnamed column\n",
    "combined_heavy.drop(columns=['post_location_utc', 'encoded'], inplace=True)\n",
    "\n",
    "# Renaming misnamaed column\n",
    "cols_old = list(combined_heavy.columns)\n",
    "cols = [cols_old[0]] + ['post_body'] + cols_old[2:]\n",
    "\n",
    "cols = {cols_old[i]:cols[i] for i in range(len(cols))}\n",
    "\n",
    "combined_heavy.rename(columns=cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "65e5aff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(251, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_time_utc</th>\n",
       "      <th>post_body</th>\n",
       "      <th>response_body</th>\n",
       "      <th>response_time</th>\n",
       "      <th>root_post</th>\n",
       "      <th>post_time</th>\n",
       "      <th>response_time_utc</th>\n",
       "      <th>encoded_clean</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1635433244</td>\n",
       "      <td>Hell's canyon?</td>\n",
       "      <td>Warm!</td>\n",
       "      <td>2021-10-28 16:04:51</td>\n",
       "      <td>post_1</td>\n",
       "      <td>2021-10-28 08:00:44</td>\n",
       "      <td>1635462291</td>\n",
       "      <td>+1</td>\n",
       "      <td>34.918075</td>\n",
       "      <td>-112.278501</td>\n",
       "      <td>hell canyon, arizona, usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1635433325</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>Getting colder!</td>\n",
       "      <td>2021-10-28 16:04:40</td>\n",
       "      <td>post_1</td>\n",
       "      <td>2021-10-28 08:02:05</td>\n",
       "      <td>1635462280</td>\n",
       "      <td>-1</td>\n",
       "      <td>to_delete</td>\n",
       "      <td>to_delete</td>\n",
       "      <td>to_fix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1635443314</td>\n",
       "      <td>Maine</td>\n",
       "      <td>Cold!</td>\n",
       "      <td>2021-10-28 16:03:17</td>\n",
       "      <td>post_1</td>\n",
       "      <td>2021-10-28 10:48:34</td>\n",
       "      <td>1635462197</td>\n",
       "      <td>-1</td>\n",
       "      <td>45.253783</td>\n",
       "      <td>-69.445469</td>\n",
       "      <td>maine, usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1635452573</td>\n",
       "      <td>Sterling, CO</td>\n",
       "      <td>This guess is a little bit chilly</td>\n",
       "      <td>2021-10-28 16:02:08</td>\n",
       "      <td>post_1</td>\n",
       "      <td>2021-10-28 13:22:53</td>\n",
       "      <td>1635462128</td>\n",
       "      <td>-1</td>\n",
       "      <td>40.625541</td>\n",
       "      <td>-103.207709</td>\n",
       "      <td>sterling, co 80751, usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1635450547</td>\n",
       "      <td>Joshua Tree, California</td>\n",
       "      <td>Cold!</td>\n",
       "      <td>2021-10-28 16:01:29</td>\n",
       "      <td>post_1</td>\n",
       "      <td>2021-10-28 12:49:07</td>\n",
       "      <td>1635462089</td>\n",
       "      <td>-1</td>\n",
       "      <td>34.134728</td>\n",
       "      <td>-116.313066</td>\n",
       "      <td>joshua tree, ca 92252, usa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_time_utc                post_body                      response_body  \\\n",
       "0     1635433244           Hell's canyon?                              Warm!   \n",
       "1     1635433325                [deleted]                    Getting colder!   \n",
       "2     1635443314                    Maine                              Cold!   \n",
       "3     1635452573             Sterling, CO  This guess is a little bit chilly   \n",
       "4     1635450547  Joshua Tree, California                              Cold!   \n",
       "\n",
       "        response_time root_post           post_time  response_time_utc  \\\n",
       "0 2021-10-28 16:04:51    post_1 2021-10-28 08:00:44         1635462291   \n",
       "1 2021-10-28 16:04:40    post_1 2021-10-28 08:02:05         1635462280   \n",
       "2 2021-10-28 16:03:17    post_1 2021-10-28 10:48:34         1635462197   \n",
       "3 2021-10-28 16:02:08    post_1 2021-10-28 13:22:53         1635462128   \n",
       "4 2021-10-28 16:01:29    post_1 2021-10-28 12:49:07         1635462089   \n",
       "\n",
       "  encoded_clean        lat         lon                        name  \n",
       "0            +1  34.918075 -112.278501   hell canyon, arizona, usa  \n",
       "1            -1  to_delete   to_delete                      to_fix  \n",
       "2            -1  45.253783  -69.445469                  maine, usa  \n",
       "3            -1  40.625541 -103.207709     sterling, co 80751, usa  \n",
       "4            -1  34.134728 -116.313066  joshua tree, ca 92252, usa  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(combined_heavy.shape)\n",
    "combined_heavy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "585e83f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_heavy.to_csv('reddit_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
